{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from PIL import Image\n",
    "import tifffile\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags\n",
    "\n",
    "# Use MPS if available?\n",
    "USE_MPS = False # CNN stuff doesn't work (particularly 3D CNN) with MPS. Only CUDA works.\n",
    "\n",
    "# Use Lower Quality features (bigger dataset but quite possibly shit data) for training?\n",
    "USE_LQ_FEATURES = False\n",
    "\n",
    "# Use ensemble method or use padding?\n",
    "USE_ENSEMBLE = False\n",
    "\n",
    "LOAD_WEIGHTS = True # Load pretrained weights if they exist?\n",
    "TRAIN_MODEL = False # Train model? Can train on pre-loaded weights also\n",
    "SAVE_WEIGHTS = False # Save weights after training?\n",
    "\n",
    "ENSEMBLE_WEIGHTS = \"ensemble_model_weights.pth\" # Weights for ensemble learning model\n",
    "PADDING_WEIGHTS = \"padding_model_weights.pth\" # Weights for padding based model\n",
    "\n",
    "RANDOM_SEED = 42069 # Seed to use for all random operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('mps:0') if (USE_MPS and torch.backends.mps.is_available()) else torch.device('cpu')\n",
    "\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7, 2)\n",
      "(2, 7, 2)\n",
      "(2, 7, 2)\n",
      "(6, 23, 23)\n",
      "(6, 23, 23)\n",
      "(6, 23, 23)\n",
      "(2, 3, 2)\n",
      "(2, 3, 2)\n",
      "(2, 3, 2)\n",
      "(11, 28, 30)\n",
      "(11, 28, 30)\n",
      "(11, 28, 30)\n",
      "(2, 10, 4)\n",
      "(2, 10, 4)\n",
      "(2, 10, 4)\n",
      "(12, 121, 100)\n",
      "(12, 121, 100)\n",
      "(12, 121, 100)\n",
      "(5, 23, 19)\n",
      "(5, 23, 19)\n",
      "(5, 23, 19)\n",
      "(3, 3, 14)\n",
      "(3, 3, 14)\n",
      "(3, 3, 14)\n",
      "(11, 62, 24)\n",
      "(11, 62, 24)\n",
      "(11, 62, 24)\n",
      "(2, 6, 7)\n",
      "(2, 6, 7)\n",
      "(2, 6, 7)\n",
      "(6, 34, 34)\n",
      "(6, 34, 34)\n",
      "(6, 34, 34)\n",
      "(7, 17, 31)\n",
      "(7, 17, 31)\n",
      "(7, 17, 31)\n",
      "(2, 3, 4)\n",
      "(2, 3, 4)\n",
      "(2, 3, 4)\n",
      "(4, 4, 4)\n",
      "(4, 4, 4)\n",
      "(4, 4, 4)\n",
      "(6, 16, 14)\n",
      "(6, 16, 14)\n",
      "(6, 16, 14)\n",
      "(2, 4, 3)\n",
      "(2, 4, 3)\n",
      "(2, 4, 3)\n",
      "(2, 9, 8)\n",
      "(2, 9, 8)\n",
      "(2, 9, 8)\n",
      "(3, 20, 25)\n",
      "(3, 20, 25)\n",
      "(3, 20, 25)\n",
      "(2, 9, 10)\n",
      "(2, 9, 10)\n",
      "(2, 9, 10)\n",
      "(2, 10, 12)\n",
      "(2, 10, 12)\n",
      "(2, 10, 12)\n",
      "(2, 3, 7)\n",
      "(2, 3, 7)\n",
      "(2, 3, 7)\n",
      "(2, 23, 21)\n",
      "(2, 23, 21)\n",
      "(2, 23, 21)\n",
      "(2, 7, 9)\n",
      "(2, 7, 9)\n",
      "(2, 7, 9)\n",
      "(2, 4, 7)\n",
      "(2, 4, 7)\n",
      "(2, 4, 7)\n",
      "(2, 4, 5)\n",
      "(2, 4, 5)\n",
      "(2, 4, 5)\n",
      "(10, 69, 62)\n",
      "(10, 69, 62)\n",
      "(10, 69, 62)\n",
      "(2, 6, 2)\n",
      "(2, 6, 2)\n",
      "(2, 6, 2)\n",
      "(2, 12, 11)\n",
      "(2, 12, 11)\n",
      "(2, 12, 11)\n",
      "(2, 6, 2)\n",
      "(2, 6, 2)\n",
      "(2, 6, 2)\n",
      "(5, 38, 25)\n",
      "(5, 38, 25)\n",
      "(5, 38, 25)\n",
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "(2, 15, 9)\n",
      "(2, 15, 9)\n",
      "(2, 15, 9)\n",
      "(3, 25, 22)\n",
      "(3, 25, 22)\n",
      "(3, 25, 22)\n",
      "(2, 5, 3)\n",
      "(2, 5, 3)\n",
      "(2, 5, 3)\n",
      "(2, 8, 9)\n",
      "(2, 8, 9)\n",
      "(2, 8, 9)\n",
      "(11, 88, 101)\n",
      "(11, 88, 101)\n",
      "(11, 88, 101)\n",
      "(2, 7, 9)\n",
      "(2, 7, 9)\n",
      "(2, 7, 9)\n",
      "(2, 9, 7)\n",
      "(2, 9, 7)\n",
      "(2, 9, 7)\n",
      "(11, 96, 51)\n",
      "(11, 96, 51)\n",
      "(11, 96, 51)\n",
      "(2, 6, 4)\n",
      "(2, 6, 4)\n",
      "(2, 6, 4)\n",
      "(3, 8, 11)\n",
      "(3, 8, 11)\n",
      "(3, 8, 11)\n",
      "(7, 150, 71)\n",
      "(7, 150, 71)\n",
      "(7, 150, 71)\n",
      "(5, 25, 17)\n",
      "(5, 25, 17)\n",
      "(5, 25, 17)\n",
      "(2, 4, 4)\n",
      "(2, 4, 4)\n",
      "(2, 4, 4)\n",
      "(5, 76, 74)\n",
      "(5, 76, 74)\n",
      "(5, 76, 74)\n",
      "(3, 23, 11)\n",
      "(3, 23, 11)\n",
      "(3, 23, 11)\n",
      "(3, 15, 7)\n",
      "(3, 15, 7)\n",
      "(3, 15, 7)\n",
      "(2, 8, 3)\n",
      "(2, 8, 3)\n",
      "(2, 8, 3)\n",
      "(2, 23, 24)\n",
      "(2, 23, 24)\n",
      "(2, 23, 24)\n",
      "(2, 10, 7)\n",
      "(2, 10, 7)\n",
      "(2, 10, 7)\n",
      "(3, 3, 2)\n",
      "(3, 3, 2)\n",
      "(3, 3, 2)\n",
      "(2, 13, 4)\n",
      "(2, 13, 4)\n",
      "(2, 13, 4)\n",
      "(2, 8, 3)\n",
      "(2, 8, 3)\n",
      "(2, 8, 3)\n",
      "(7, 15, 13)\n",
      "(7, 15, 13)\n",
      "(7, 15, 13)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(3, 6, 7)\n",
      "(3, 6, 7)\n",
      "(3, 6, 7)\n",
      "(2, 1, 4)\n",
      "(5, 31, 38)\n",
      "(5, 31, 38)\n",
      "(5, 31, 38)\n",
      "(2, 13, 10)\n",
      "(2, 13, 10)\n",
      "(2, 13, 10)\n",
      "(3, 19, 12)\n",
      "(3, 19, 12)\n",
      "(3, 19, 12)\n",
      "(10, 42, 38)\n",
      "(10, 42, 38)\n",
      "(10, 42, 38)\n",
      "(3, 14, 6)\n",
      "(3, 14, 6)\n",
      "(3, 14, 6)\n",
      "(2, 6, 8)\n",
      "(2, 6, 8)\n",
      "(2, 6, 8)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(15, 262, 215)\n",
      "(15, 262, 215)\n",
      "(15, 262, 215)\n",
      "(3, 11, 3)\n",
      "(3, 11, 3)\n",
      "(3, 11, 3)\n",
      "(12, 41, 69)\n",
      "(12, 41, 69)\n",
      "(12, 41, 69)\n",
      "(7, 41, 37)\n",
      "(7, 41, 37)\n",
      "(7, 41, 37)\n",
      "(3, 10, 7)\n",
      "(3, 10, 7)\n",
      "(3, 10, 7)\n",
      "(3, 9, 6)\n",
      "(3, 9, 6)\n",
      "(3, 9, 6)\n",
      "(2, 7, 2)\n",
      "(2, 7, 2)\n",
      "(2, 7, 2)\n",
      "(2, 7, 4)\n",
      "(2, 7, 4)\n",
      "(2, 7, 4)\n",
      "(3, 4, 5)\n",
      "(3, 4, 5)\n",
      "(3, 4, 5)\n",
      "(2, 42, 12)\n",
      "(2, 42, 12)\n",
      "(2, 42, 12)\n",
      "(7, 17, 8)\n",
      "(7, 17, 8)\n",
      "(7, 17, 8)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(6, 22, 16)\n",
      "(6, 22, 16)\n",
      "(6, 22, 16)\n",
      "(2, 6, 20)\n",
      "(2, 6, 20)\n",
      "(2, 6, 20)\n",
      "(3, 10, 7)\n",
      "(3, 10, 7)\n",
      "(3, 10, 7)\n",
      "(3, 10, 2)\n",
      "(3, 10, 2)\n",
      "(3, 10, 2)\n",
      "(3, 10, 16)\n",
      "(3, 10, 16)\n",
      "(3, 10, 16)\n",
      "(6, 32, 27)\n",
      "(6, 32, 27)\n",
      "(6, 32, 27)\n",
      "(3, 7, 3)\n",
      "(3, 7, 3)\n",
      "(3, 7, 3)\n",
      "(3, 13, 9)\n",
      "(3, 13, 9)\n",
      "(3, 13, 9)\n",
      "(2, 12, 5)\n",
      "(2, 12, 5)\n",
      "(2, 12, 5)\n",
      "(2, 6, 3)\n",
      "(2, 6, 3)\n",
      "(2, 6, 3)\n",
      "(2, 4, 4)\n",
      "(2, 4, 4)\n",
      "(2, 4, 4)\n",
      "(3, 15, 14)\n",
      "(3, 15, 14)\n",
      "(3, 15, 14)\n",
      "(2, 17, 10)\n",
      "(2, 17, 10)\n",
      "(2, 17, 10)\n",
      "(3, 16, 21)\n",
      "(3, 16, 21)\n",
      "(3, 16, 21)\n",
      "(3, 16, 20)\n",
      "(3, 16, 20)\n",
      "(3, 16, 20)\n",
      "(5, 19, 9)\n",
      "(5, 19, 9)\n",
      "(5, 19, 9)\n",
      "(3, 27, 21)\n",
      "(3, 27, 21)\n",
      "(3, 27, 21)\n",
      "(3, 16, 8)\n",
      "(3, 16, 8)\n",
      "(3, 16, 8)\n",
      "(2, 9, 7)\n",
      "(2, 9, 7)\n",
      "(2, 9, 7)\n",
      "(2, 12, 22)\n",
      "(2, 12, 22)\n",
      "(2, 12, 22)\n",
      "(2, 7, 8)\n",
      "(2, 7, 8)\n",
      "(2, 7, 8)\n",
      "(2, 7, 5)\n",
      "(2, 7, 5)\n",
      "(2, 7, 5)\n",
      "(2, 4, 6)\n",
      "(2, 4, 6)\n",
      "(2, 4, 6)\n",
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "(2, 10, 18)\n",
      "(2, 10, 18)\n",
      "(2, 10, 18)\n",
      "(2, 8, 3)\n",
      "(2, 8, 3)\n",
      "(2, 8, 3)\n",
      "(2, 23, 25)\n",
      "(2, 23, 25)\n",
      "(2, 23, 25)\n",
      "(2, 11, 11)\n",
      "(2, 11, 11)\n",
      "(2, 11, 11)\n",
      "(3, 8, 8)\n",
      "(3, 8, 8)\n",
      "(3, 8, 8)\n",
      "(2, 4, 4)\n",
      "(2, 4, 4)\n",
      "(2, 4, 4)\n",
      "(3, 8, 8)\n",
      "(3, 8, 8)\n",
      "(3, 8, 8)\n",
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "(2, 25, 15)\n",
      "(2, 25, 15)\n",
      "(2, 25, 15)\n",
      "(2, 9, 11)\n",
      "(2, 9, 11)\n",
      "(2, 9, 11)\n",
      "(2, 9, 3)\n",
      "(2, 9, 3)\n",
      "(2, 9, 3)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 12, 3)\n",
      "(2, 12, 3)\n",
      "(2, 12, 3)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 4, 2)\n",
      "(2, 9, 7)\n",
      "(2, 9, 7)\n",
      "(2, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "# DF and Image loading from CSV\n",
    "\n",
    "hq_csv_file_path = 'full_Table_HIGH_QUAL.csv'\n",
    "lq_csv_file_path = 'full_Table_STRIPPED_CLEANED.csv'\n",
    "image_folder_path = \"./Images_Of_Networks/tiff/\"\n",
    "\n",
    "df_file_path = lq_csv_file_path if USE_LQ_FEATURES else hq_csv_file_path\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "df = pd.read_csv(df_file_path)\n",
    "\n",
    "# Function to load images\n",
    "def load_tiff_as_tensor(file_name):\n",
    "    file_path = os.path.join(image_folder_path, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        image_array = tifffile.imread(file_path)\n",
    "        # Convert the array to float32 before creating the tensor\n",
    "        image_array = image_array.astype('float32')\n",
    "        \n",
    "        # TEMPORARY!! to ensure there are no images w just one pixel in any dimension\n",
    "        for i in range (3):\n",
    "            if (image_array.shape[i] < 2):\n",
    "                return None\n",
    "            else:\n",
    "                print(image_array.shape)\n",
    "        \n",
    "        return torch.from_numpy(image_array).float()\n",
    "    return None\n",
    "\n",
    "# Update DataFrame 'image' column loading\n",
    "df['image'] = df['file_name'].apply(load_tiff_as_tensor)\n",
    "\n",
    "# Drop the 'file_name' column\n",
    "df.drop('file_name', axis=1, inplace=True)\n",
    "\n",
    "# Delete rows without images\n",
    "df = df.dropna(subset=['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest dimensions: x = 15, y = 262, z = 215\n",
      "Smallest dimensions: x = 2, y = 3, z = 2\n",
      "Min dimensions:  (2, 3, 2)\n",
      "Max dimensions:  (15, 262, 215)\n",
      "Train Size: 102\n",
      "Test Size: 12\n",
      "Total Dataset Size: 114\n"
     ]
    }
   ],
   "source": [
    "# Check the largest and smallest x, y, z dimension of each image in the dfs\n",
    "\n",
    "# Max dimensions will be used to pad all images to be the same size as the max_dimensions\n",
    "# so that the network has uniform image sizes to train on\n",
    "\n",
    "# and\n",
    "\n",
    "# Min dimensions will be used to split all images into multiple images of min_dimension size\n",
    "# for ensemble learning\n",
    "\n",
    "def get_image_dimensions(image):\n",
    "    # Get x and y dimensions from the image size\n",
    "    x_dim, y_dim, z_dim = image.size(0), image.size(1), image.size(2)\n",
    "    return x_dim, y_dim, z_dim\n",
    "\n",
    "# Extract dimensions of all images\n",
    "dimensions = df['image'].apply(get_image_dimensions)\n",
    "\n",
    "# Separate into individual lists for x, y, and z\n",
    "x_dims = [dim[0] for dim in dimensions]\n",
    "y_dims = [dim[1] for dim in dimensions]\n",
    "z_dims = [dim[2] for dim in dimensions]\n",
    "\n",
    "# Find independent max and min dimensions\n",
    "max_x, max_y, max_z = max(x_dims), max(y_dims), max(z_dims)\n",
    "min_x, min_y, min_z = min(x_dims), min(y_dims), min(z_dims)\n",
    "\n",
    "print(f'Largest dimensions: x = {max_x}, y = {max_y}, z = {max_z}')\n",
    "print(f'Smallest dimensions: x = {min_x}, y = {min_y}, z = {min_z}')\n",
    "\n",
    "# Use these dimensions to set up the padding correctly\n",
    "# Note: We need to use max_x, max_y, max_z for padding all images to the same size\n",
    "max_dims = (max_x, max_y, max_z)\n",
    "min_dims = (min_x, min_y, min_z)\n",
    "\n",
    "print(\"Min dimensions: \", min_dims)\n",
    "print(\"Max dimensions: \", max_dims)\n",
    "\n",
    "# Now split data into train and test set (stratified)\n",
    "feature_to_predict = 'cell_group'\n",
    "\n",
    "# Now, perform the split using the binned feature for stratification\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED, stratify=df[feature_to_predict])\n",
    "\n",
    "print(\"Train Size:\", len(train_df))\n",
    "print(\"Test Size:\", len(test_df))\n",
    "\n",
    "print(\"Total Dataset Size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_dims, min_dims, use_ensemble):\n",
    "        self.max_dims = max_dims\n",
    "        self.min_dims = min_dims\n",
    "        self.use_ensemble = use_ensemble\n",
    "        if not use_ensemble:\n",
    "            self.dataframe = dataframe\n",
    "        else:\n",
    "            # Preprocess dataframe to expand sub-images into separate rows\n",
    "            expanded_data = []\n",
    "            for idx, row in dataframe.iterrows():\n",
    "                image_tensor = row['image']  # Assuming this is already a tensor\n",
    "                sub_images_tensors = self.split_image(image_tensor)\n",
    "                for sub_img in sub_images_tensors:\n",
    "                    # Copy numerical features for each sub-image\n",
    "                    new_row = row.drop('image').to_dict()\n",
    "                    new_row['image'] = sub_img / 255  # Normalize sub-image\n",
    "                    expanded_data.append(new_row)\n",
    "            self.dataframe = pd.DataFrame(expanded_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image_tensor = row['image']  # This is already a tensor, normalized if in ensemble mode\n",
    "\n",
    "        # Extract label, the feature to predict\n",
    "        label = row['cell_group']\n",
    "\n",
    "        # Extract numerical features\n",
    "        numerical_features = torch.tensor(row.drop(['image', 'cell_group'], errors='ignore').values.astype(np.float32))\n",
    "\n",
    "        if not self.use_ensemble:\n",
    "            # If not in ensemble mode, pad and normalize the image tensor\n",
    "            image_tensor = self.pad_image(image_tensor) / 255\n",
    "        else:\n",
    "            # If in ensemble mode, image_tensor is already a normalized sub-image tensor,\n",
    "            # so there's no need for additional processing here.\n",
    "            pass\n",
    "\n",
    "        return image_tensor, numerical_features, label\n",
    "\n",
    "    def pad_image(self, image):\n",
    "        # Assuming image is a tensor\n",
    "        current_x, current_y, current_z = image.shape\n",
    "        max_x, max_y, max_z = self.max_dims\n",
    "\n",
    "        # Calculate padding\n",
    "        pad_x = max_x - current_x\n",
    "        pad_y = max_y - current_y\n",
    "        pad_z = max_z - current_z\n",
    "\n",
    "        # Apply padding\n",
    "        # PyTorch's functional pad expects padding in reverse order of dimensions and for all dimensions\n",
    "        image_padded = F.pad(image, (0, pad_z, 0, pad_y, 0, pad_x), 'constant', 0)\n",
    "        return image_padded\n",
    "\n",
    "    def split_image(self, image):\n",
    "        min_x, min_y, min_z = self.min_dims\n",
    "        sub_images = []\n",
    "        for x in range(0, image.shape[0] - min_x + 1, min_x):\n",
    "            for y in range(0, image.shape[1] - min_y + 1, min_y):\n",
    "                for z in range(0, image.shape[2] - min_z + 1, min_z):\n",
    "                    sub_img = image[x:x+min_x, y:y+min_y, z:z+min_z]\n",
    "                    sub_images.append(sub_img)\n",
    "        return sub_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_numerical_features, image_dims, use_ensemble):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        self.use_ensemble = use_ensemble\n",
    "        \n",
    "        # Unpack image dimensions\n",
    "        self.x_dim, self.y_dim, self.z_dim = image_dims\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Adaptive pool to make the output size fixed before the fully connected layers\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool3d((5, 5, 5))\n",
    "        \n",
    "        # Calculate the size for the first fully connected layer\n",
    "        fc1_input_size = 5 * 5 * 5 * 64 + num_numerical_features\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(fc1_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Output size is 1 for binary classification\n",
    "        \n",
    "    def forward(self, image_tensors, numerical_features):\n",
    "        if self.use_ensemble:\n",
    "            predictions = []\n",
    "            for image_tensor in image_tensors:\n",
    "                # Add both batch and channel dimensions for 3D grayscale image\n",
    "                image_tensor = image_tensor.unsqueeze(1)  # Now it's [Batch Size, 1, D, H, W]\n",
    "                features = self.extract_features(image_tensor)\n",
    "                combined_features = torch.cat((features, numerical_features), dim=1)\n",
    "                x = F.relu(self.fc1(combined_features))\n",
    "                prediction = torch.sigmoid(self.fc2(x))\n",
    "                predictions.append(prediction)\n",
    "            final_prediction = torch.max(torch.stack(predictions), dim=0)[0]\n",
    "            \n",
    "            # THE ABOVE BIT FOR ENSEMBLE PROLLY NEEDS MORE WORK! PROBABLY DOESN'T QUITE WORK YET\n",
    "        else:\n",
    "            # Add both batch and channel dimensions for 3D grayscale image\n",
    "            image_tensors = image_tensors.unsqueeze(1)  # Now it's [Batch Size, 1, D, H, W]\n",
    "            features = self.extract_features(image_tensors)\n",
    "            combined_features = torch.cat((features, numerical_features), dim=1)\n",
    "            x = F.relu(self.fc1(combined_features))\n",
    "            final_prediction = torch.sigmoid(self.fc2(x))\n",
    "        return final_prediction\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        # Convolutional layers with ReLU and MaxPool\n",
    "        x = F.max_pool3d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool3d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool3d(F.relu(self.conv3(x)), 2)\n",
    "        \n",
    "        # Adaptive pooling\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=10, device=device):\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            # Unpack data\n",
    "            if model.use_ensemble:\n",
    "                images, numerical_features, labels = zip(*data)\n",
    "                images = [img.to(device) for sublist in images for img in sublist]  # Flatten list of lists\n",
    "                numerical_features = torch.cat(numerical_features).to(device)\n",
    "                labels = torch.cat(labels).to(device)\n",
    "            else:\n",
    "                images, numerical_features, labels = data\n",
    "                images, numerical_features, labels = images.to(device), numerical_features.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            if model.use_ensemble:\n",
    "                outputs = torch.stack([model(img.unsqueeze(0), numerical_features[i].unsqueeze(0)) for i, img in enumerate(images)])\n",
    "                outputs = outputs.mean(dim=0).squeeze()  # Aggregate by averaging\n",
    "            else:\n",
    "                outputs = model(images, numerical_features).squeeze()\n",
    "\n",
    "            # Calculate loss and backpropagate\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                # Unpack data\n",
    "                if model.use_ensemble:\n",
    "                    images, numerical_features, labels = zip(*data)\n",
    "                    images = [img.to(device) for sublist in images for img in sublist]  # Flatten list of lists\n",
    "                    numerical_features = torch.cat(numerical_features).to(device)\n",
    "                    labels = torch.cat(labels).to(device)\n",
    "                else:\n",
    "                    images, numerical_features, labels = data\n",
    "                    images, numerical_features, labels = images.to(device), numerical_features.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                if model.use_ensemble:\n",
    "                    outputs = torch.stack([model(img.unsqueeze(0), numerical_features[i].unsqueeze(0)) for i, img in enumerate(images)])\n",
    "                    outputs = outputs.max(dim=0)[0].squeeze()  # Aggregate by taking max\n",
    "                else:\n",
    "                    outputs = model(images, numerical_features).squeeze()\n",
    "\n",
    "                predicted = outputs > 0.5\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy on test set: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CustomDatasets\n",
    "train_dataset = CustomDataset(train_df, max_dims, min_dims, USE_ENSEMBLE)\n",
    "test_dataset = CustomDataset(test_df, max_dims, min_dims, USE_ENSEMBLE)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = CustomCNN(num_numerical_features=len(train_df.drop(['image', 'cell_group'], axis=1).columns),\n",
    "                  image_dims=min_dims if USE_ENSEMBLE else max_dims,\n",
    "                  use_ensemble=USE_ENSEMBLE)\n",
    "model.to(device)\n",
    "\n",
    "# Load pretrained weights if available and desired\n",
    "weights_path = ENSEMBLE_WEIGHTS if USE_ENSEMBLE else PADDING_WEIGHTS\n",
    "if LOAD_WEIGHTS and os.path.isfile(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "\n",
    "# Train the model if needed\n",
    "if TRAIN_MODEL:\n",
    "    train_model(model, train_loader, test_loader, num_epochs=10, device=device)\n",
    "    if SAVE_WEIGHTS:\n",
    "        torch.save(model.state_dict(), weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "accuracies = []  # This will store True for correct predictions and False for incorrect predictions\n",
    "pixel_counts_accuracies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, row in test_df.iterrows():\n",
    "        # Create a single-row DataFrame from the current row\n",
    "        single_row_df = pd.DataFrame([row])\n",
    "\n",
    "        # Initialize a CustomDataset instance with this single-row DataFrame\n",
    "        single_row_dataset = CustomDataset(single_row_df, max_dims, min_dims, USE_ENSEMBLE)\n",
    "\n",
    "        # Create a DataLoader for this dataset with a batch size of 1\n",
    "        single_row_loader = DataLoader(single_row_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        # Run inference using this DataLoader\n",
    "        for images, numerical_features, labels in single_row_loader:\n",
    "            images, numerical_features, labels = images.to(device), numerical_features.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images, numerical_features).squeeze()\n",
    "            predicted = outputs > 0.5  # Threshold for binary classification\n",
    "\n",
    "            # Determine the correctness of each prediction\n",
    "            is_correct = (predicted == labels).item()\n",
    "            accuracies.append(is_correct)\n",
    "\n",
    "        # Determine the pixel count for the current datapoint\n",
    "        pixel_count = math.prod(row['image'].shape)\n",
    "        pixel_counts_accuracies.append(pixel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "recalls = []  # This will store True for correct predictions and False for incorrect predictions\n",
    "pixel_counts_recalls = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, row in train_df.iterrows():\n",
    "        # Create a single-row DataFrame from the current row\n",
    "        single_row_df = pd.DataFrame([row])\n",
    "\n",
    "        # Initialize a CustomDataset instance with this single-row DataFrame\n",
    "        single_row_dataset = CustomDataset(single_row_df, max_dims, min_dims, USE_ENSEMBLE)\n",
    "\n",
    "        # Create a DataLoader for this dataset with a batch size of 1\n",
    "        single_row_loader = DataLoader(single_row_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        # Run inference using this DataLoader\n",
    "        for images, numerical_features, labels in single_row_loader:\n",
    "            images, numerical_features, labels = images.to(device), numerical_features.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images, numerical_features).squeeze()\n",
    "            predicted = outputs > 0.5  # Threshold for binary classification\n",
    "\n",
    "            # Determine the correctness of each prediction\n",
    "            is_correct = (predicted == labels).item()\n",
    "            recalls.append(is_correct)\n",
    "\n",
    "        # Determine the pixel count for the current datapoint\n",
    "        pixel_count = math.prod(row['image'].shape)\n",
    "        pixel_counts_recalls.append(pixel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "Blue",
          "line": {
           "color": "MediumBlue",
           "width": 2
          },
          "size": 12
         },
         "mode": "markers",
         "name": "Correct",
         "type": "scatter",
         "x": [
          126,
          54,
          264,
          32,
          120,
          80,
          48,
          759,
          74550,
          126,
          33948,
          10619,
          48,
          684,
          53856,
          20,
          192,
          126,
          16368,
          30,
          64,
          140,
          24,
          480,
          48,
          9240,
          126,
          3689,
          28,
          1008,
          18,
          32,
          855,
          360,
          145200,
          630,
          70,
          315,
          16,
          264,
          20,
          1701,
          96,
          24,
          28120,
          270,
          2185,
          16,
          966,
          1008,
          384,
          16,
          1500,
          5890,
          240,
          48,
          1104,
          162,
          260,
          12,
          210,
          48,
          1365,
          180,
          56,
          528,
          97768,
          42,
          1344,
          104,
          16,
          32,
          192,
          42780,
          1650,
          28,
          24,
          84,
          210,
          144,
          3174,
          56,
          1150,
          63,
          144,
          2125,
          126,
          242,
          15960,
          16,
          952,
          6936,
          40,
          126,
          240,
          2112,
          198,
          112
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        },
        {
         "marker": {
          "color": "Red",
          "line": {
           "color": "DarkRed",
           "width": 2
          },
          "size": 12
         },
         "mode": "markers",
         "name": "Incorrect",
         "type": "scatter",
         "x": [
          99,
          36,
          351,
          340
         ],
         "y": [
          0,
          0,
          0,
          0
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correctness vs. Number of Pixels in Image (Recall)"
        },
        "xaxis": {
         "title": {
          "text": "Number of Pixels"
         },
         "type": "log"
        },
        "yaxis": {
         "ticktext": [
          "Incorrect",
          "Correct"
         ],
         "tickvals": [
          0,
          1
         ],
         "title": {
          "text": "Correctness"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add points for correct predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[pixel_counts_recalls[i] for i in range(len(recalls)) if recalls[i]],\n",
    "    y=[1 for i in range(len(recalls)) if recalls[i]],  # Use 1 as a dummy value to represent correct predictions\n",
    "    mode='markers',\n",
    "    name='Correct',\n",
    "    marker=dict(color='Blue', size=12, line=dict(color='MediumBlue', width=2))\n",
    "))\n",
    "\n",
    "# Add points for incorrect predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[pixel_counts_recalls[i] for i in range(len(recalls)) if not recalls[i]],\n",
    "    y=[0 for i in range(len(recalls)) if not recalls[i]],  # Use 0 as a dummy value to represent incorrect predictions\n",
    "    mode='markers',\n",
    "    name='Incorrect',\n",
    "    marker=dict(color='Red', size=12, line=dict(color='DarkRed', width=2))\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Correctness vs. Number of Pixels in Image (Recall)',\n",
    "    xaxis_title='Number of Pixels',\n",
    "    xaxis_type='log',  # Set the x-axis to a logarithmic scale\n",
    "    yaxis_title='Correctness',\n",
    "    yaxis=dict(tickvals=[0, 1], ticktext=['Incorrect', 'Correct'])\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "Blue",
          "line": {
           "color": "MediumBlue",
           "width": 2
          },
          "size": 12
         },
         "mode": "markers",
         "name": "Correct",
         "type": "scatter",
         "x": [
          4750,
          20,
          24,
          5184,
          60,
          844950,
          252,
          72,
          126,
          960,
          750
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        },
        {
         "marker": {
          "color": "Red",
          "line": {
           "color": "DarkRed",
           "width": 2
          },
          "size": 12
         },
         "mode": "markers",
         "name": "Incorrect",
         "type": "scatter",
         "x": [
          60
         ],
         "y": [
          0
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correctness vs. Number of Pixels in Image (Accuracy)"
        },
        "xaxis": {
         "title": {
          "text": "Number of Pixels"
         },
         "type": "log"
        },
        "yaxis": {
         "ticktext": [
          "Incorrect",
          "Correct"
         ],
         "tickvals": [
          0,
          1
         ],
         "title": {
          "text": "Correctness"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add points for correct predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[pixel_counts_accuracies[i] for i in range(len(accuracies)) if accuracies[i]],\n",
    "    y=[1 for i in range(len(accuracies)) if accuracies[i]],  # Use 1 as a dummy value to represent correct predictions\n",
    "    mode='markers',\n",
    "    name='Correct',\n",
    "    marker=dict(color='Blue', size=12, line=dict(color='MediumBlue', width=2))\n",
    "))\n",
    "\n",
    "# Add points for incorrect predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[pixel_counts_accuracies[i] for i in range(len(accuracies)) if not accuracies[i]],\n",
    "    y=[0 for i in range(len(accuracies)) if not accuracies[i]],  # Use 0 as a dummy value to represent incorrect predictions\n",
    "    mode='markers',\n",
    "    name='Incorrect',\n",
    "    marker=dict(color='Red', size=12, line=dict(color='DarkRed', width=2))\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Correctness vs. Number of Pixels in Image (Accuracy)',\n",
    "    xaxis_title='Number of Pixels',\n",
    "    xaxis_type='log',  # Set the x-axis to a logarithmic scale\n",
    "    yaxis_title='Correctness',\n",
    "    yaxis=dict(tickvals=[0, 1], ticktext=['Incorrect', 'Correct'])\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
